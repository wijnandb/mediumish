---
layout: post
title: "Zorgen OM over deepfakes: 'Risico op oplichting en afpersing'"
date: Sat, 07 Sep 2019 08:30:07 +0200
category: tech
externe_link: "https://nos.nl/l/2300688"
feature_image: "https://nos.nl/data/image/2019/09/07/575586/1008x567.jpg"
aantal: 635
unieke: 347
bron: NOS
---

<p>Het Openbaar Ministerie maakt zich zorgen over zogeheten deepfakes. Dat zijn filmpjes die met behulp van slimme algoritmes zijn gemanipuleerd. Je kunt iemands hoofd vervangen door dat van iemand anders, of iemand hele andere dingen laten zeggen.</p>
<p>"We moeten beseffen dat als we iets zien, we dat niet meer kunnen geloven", zegt officier van justitie Lodewijk van Zwieten. "Straks kun je makkelijk iets in beeld brengen terwijl het niet echt is gebeurd."</p>
<p>Je kan politici bijvoorbeeld allemaal nep-uitspraken laten doen: </p>
<p>Het wordt steeds makkelijker om deepfake-filmpjes te maken. Afgelopen week ging in China een app viral waarmee iedereen zijn hoofd in een filmscène naar keuze kan plaatsen. Die app is in Nederland niet te downloaden; voor activeren is een Chinees telefoonnummer nodig.</p>
<p>"Dit soort apps is leuk, maar als je dat soort filmpjes gebruikt om mensen een hak te zetten, ga je een grens over", zegt Van Zwieten. De officier van justitie vreest dat dat realiteit wordt als het steeds makkelijker wordt om zelf nepfilmpjes te maken.</p>
<p>Vaak is daarvoor - anders dan bij de Chinese app - nog wel enige expertise vereist, maar de kans is groot dat dat niet zo blijft. "Als we allemaal een app op onze telefoon hebben waarmee dit kan, wordt het makkelijk om een filmpje te maken waarop je iemand anders iets strafbaars laat doen." En dat kan strafbaar zijn, bijvoorbeeld als smaad of laster.</p>
<h2>Chantage</h2>
<p>Onderzoeker Theo Gevers van de Universiteit van Amsterdam deelt de vrees voor deepfakes. "Zolang het bij leuke apps blijft, is het vrij onschuldig", zegt Gevers. "Maar als het wordt toegepast op bijvoorbeeld chantage, is dat heel gevaarlijk."</p>
<p>En de ontwikkelingen gaan snel. "Er zijn nu dingen mogelijk die een halfjaar geleden nog niet konden. En over een halfjaar tot een jaar kun je waarschijnlijk niet meer met het blote oog zien of een filmpje een deepfake is", zegt Gevers, die zelf werkt aan software die deepfakes herkent.</p>
<p>Op dit moment is het lastigste nog het vervalsen van audio: daarvoor is veel materiaal van iemands stem nodig, al zijn er berichten dat een bedrijf 240.000 dollar verloor omdat iemand zich met vervalste stem voordeed als directeur.</p>
<p>Nu al vinden bekende vrouwen - in de praktijk altijd vrouwen - zich soms al zonder toestemming terug in een pornofilm, omdat iemand hun hoofd erin heeft geplakt. Ook een bekende Nederlandse presentatrice overkwam dat onlangs.</p>
<p>Volgens Van Zwieten bestaat het risico dat, naarmate de techniek laagdrempeliger wordt, ook "hitsige tieners" op schoolpleinen dat soort filmpjes van elkaar gaan maken. En dat kan strafbaar zijn, omdat ook virtuele porno met minderjarigen in Nederland is verboden.</p>
<p>Ook zouden nepfilmpjes kunnen worden gebruikt om iemand af te persen: als hij of zij niet betaalt, wordt het filmpje verspreid. Of iemand wordt per ongeluk opgepakt, omdat het op een filmpje lijkt alsof hij iets strafbaars doet. Maar buitenlandse overheden zouden bijvoorbeeld ook nepnieuws kunnen verspreiden om verkiezingen te beïnvloeden.</p>
<h2>Koffiedik</h2>
<p>"Het is koffiedik kijken hoe groot deze technologie gaat worden", zegt Van Zwieten. "Maar als je kijkt hoeveel er op sociale media wordt bedreigd en beledigd, dan maak ik me zorgen om deze technologie."</p>
<p>Een voorbeeld van een deepfake:</p>
<p>Verbieden is wat hem betreft niet aan de orde. "Sociale media worden ook gebruikt voor bedreigingen, maar zijn ook niet verboden. Het gaat niet om de techniek, maar om wat je ermee doet."</p>
<p>Ook onderzoeker Gevers is niet voor een verbod. "Er zijn genoeg positieve toepassingen te bedenken. Natuurlijk voor leuke apps, maar ook voor educatieve of psychologische doeleinden."</p>
<p>Zo zouden scholieren les kunnen krijgen van tot leven gewekte historische figuren. Ook zouden nabestaanden virtueel kunnen praten met hun overleden dierbaren.</p>
<p>De officier van justitie denkt dat nieuwe regelgeving sowieso niet nodig is. "We komen er wel met het bestaande strafrecht. Maar we moeten wel een debat hebben over deze technologie."</p>
